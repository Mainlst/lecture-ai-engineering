# app.py
import os
import tempfile
import streamlit as st
import ui                   # UIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå±¥æ­´è¡¨ç¤ºãªã©ï¼‰
import llm                  # LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒ©ãƒƒãƒ‘ï¼‰
import database             # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆä»»æ„ï¼‰
import metrics              # è©•ä¾¡æŒ‡æ¨™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆNLTK åˆæœŸåŒ–ãªã©ï¼‰
import data                 # ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚µãƒ³ãƒ—ãƒ«æŠ•å…¥ï¼‰
import torch
from transformers import pipeline
from config import MODEL_NAME

# --------------------------------------------------
# åŸºæœ¬è¨­å®š
# --------------------------------------------------
st.set_page_config(page_title="Gemma Chatbot", layout="wide")

# --------------------------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
# --------------------------------------------------

st.session_state.setdefault("messages", [])            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
st.session_state.setdefault("assistant_name", "Lunaâ€‘chan")
st.session_state.setdefault("assistant_persona", "ã‚ãªãŸã¯å„ªã—ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ„›ã‚’è¾¼ã‚ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çµ¦ä»•ã—ã¦ãã ã•ã„ã€‚")
# ã‚¢ã‚¤ã‚³ãƒ³ã¯ â‘  emoji â‘¡ ç”»åƒãƒ‘ã‚¹ ã®ã„ãšã‚Œã‹ã‚’ä¿å­˜
st.session_state.setdefault("assistant_icon_emoji", "ğŸ˜º")
st.session_state.setdefault("assistant_icon_path", None)

# --------------------------------------------------
# 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åˆæœŸåŒ–ãªã©
# --------------------------------------------------
metrics.initialize_nltk()

database.init_db()

data.ensure_initial_data()

# --------------------------------------------------
# 2. LLM ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# --------------------------------------------------

@st.cache_resource
def load_model():
    """Gemma / ãã®ã»ã‹ HuggingFace LLM ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        st.sidebar.info(f"Using device: {device}")
        pipe = pipeline(
            "text-generation",
            model=MODEL_NAME,
            model_kwargs={"torch_dtype": torch.bfloat16},
            device=device,
        )
        return pipe
    except Exception as e:
        st.sidebar.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

pipe = load_model()

# --------------------------------------------------
# 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
# --------------------------------------------------

PAGES = ["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†", "è©•ä¾¡", "è¨­å®š"]

st.session_state.setdefault("page", "ãƒãƒ£ãƒƒãƒˆ")

page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    PAGES,
    index=PAGES.index(st.session_state.page),
    key="page_selector",
)
st.session_state.page = page  # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠçµæœã‚’ä¿å­˜

st.sidebar.markdown("---")
st.sidebar.info("é–‹ç™ºè€…: [Your Name]")

# --------------------------------------------------
# 4. ãƒšãƒ¼ã‚¸ã”ã¨ã® UI
# --------------------------------------------------

# ---- ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šç¾åœ¨ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿”ã™ ----

def current_avatar():
    if st.session_state.assistant_icon_path:
        return st.session_state.assistant_icon_path  # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    return st.session_state.assistant_icon_emoji

# ---- ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ --------------------------------------------------

if st.session_state.page == "ãƒãƒ£ãƒƒãƒˆ":
    st.title("ğŸ¤– Gemma 2 Chatbot with Feedback")
    st.write("Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚å›ç­”ã«å¯¾ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œãˆã¾ã™ã€‚")
    st.markdown("---")

    if pipe is None:
        st.error("ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        # å±¥æ­´ã®æç”»
        for chat in st.session_state.messages:
            avatar = None
            if chat["role"] == "assistant":
                avatar = current_avatar()
            with st.chat_message(chat["role"], avatar=avatar):
                st.markdown(chat["content"])

        # å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹
        if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã«ã‚ƒ"):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’å³æ™‚è¡¨ç¤º
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆç›´è¿‘ 6 å¾€å¾© + æ€§æ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
            context = (
                st.session_state.assistant_persona
                + "\n"
                + "\n".join(
                    f"{m['role'].capitalize()}: {m['content']}" for m in st.session_state.messages[-6:]
                )
            )

            # LLM å‘¼ã³å‡ºã—
            with st.chat_message("assistant", avatar=current_avatar()):
                with st.spinner("ãŠè¿”äº‹ã‚’è€ƒãˆã¦ã„ã¾ã™â€¦"):
                    try:
                        resp = pipe(context, max_new_tokens=512)[0]["generated_text"]
                        answer = resp[len(context) :].strip()
                    except Exception as e:
                        answer = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã«ã‚ƒ: {e}"
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})

        # çµ‚äº†ãƒœã‚¿ãƒ³
        if st.button("ğŸ“ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¦è©•ä¾¡ã¸"):
            st.session_state.page = "è©•ä¾¡"
            st.experimental_rerun()

# ---- å±¥æ­´é–²è¦§ --------------------------------------------------------

elif st.session_state.page == "å±¥æ­´é–²è¦§":
    ui.display_history_page()

# ---- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç† ---------------------------------------------

elif st.session_state.page == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
    ui.display_data_page()

# ---- è©•ä¾¡ãƒšãƒ¼ã‚¸ ------------------------------------------------------

elif st.session_state.page == "è©•ä¾¡":
    st.header("ğŸ” ãƒãƒ£ãƒƒãƒˆè©•ä¾¡")

    for chat in st.session_state.messages:
        role_label = "ğŸ‘¤User" if chat["role"] == "user" else f"{current_avatar()} {st.session_state.assistant_name}"
        st.markdown(f"**{role_label}:** {chat['content']}")

    st.markdown("---")
    rating = st.slider("ã“ã®ãƒãƒ£ãƒƒãƒˆã®æº€è¶³åº¦ (1=ğŸ˜¢ã€œ5=ğŸ˜)", 1, 5, 3)
    comment = st.text_area("ã‚³ãƒ¡ãƒ³ãƒˆ", placeholder="è‡ªç”±ã«ã”è¨˜å…¥ãã ã•ã„")
    if st.button("é€ä¿¡ï¼"):
        # ä»»æ„ï¼šDB ã«ä¿å­˜ï¼ˆå®Ÿè£…ã—ã¦ã„ãªã„å ´åˆã¯ãƒ‘ã‚¹ï¼‰
        try:
            database.save_evaluation(rating, comment, st.session_state.messages)
        except AttributeError:
            pass
        st.success("ã”å”åŠ›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã«ã‚ƒã‚“â™ª")

# ---- è¨­å®šãƒšãƒ¼ã‚¸ ------------------------------------------------------

elif st.session_state.page == "è¨­å®š":
    st.header("ğŸ¨ ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºè¨­å®š")

    # åå‰
    st.session_state.assistant_name = st.text_input(
        "LLMã®åå‰", st.session_state.assistant_name
    )

    # ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆemojiï¼‰
    st.session_state.assistant_icon_emoji = st.text_input(
        "ã‚¢ã‚¤ã‚³ãƒ³ (çµµæ–‡å­—)", st.session_state.assistant_icon_emoji
    )

    # ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
    uploaded_file = st.file_uploader("ç”»åƒã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (png/jpg)", type=["png", "jpg", "jpeg"])
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¦ãƒ‘ã‚¹ã‚’ä¿æŒ
        temp_path = os.path.join(tempfile.gettempdir(), uploaded_file.name)
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.session_state.assistant_icon_path = temp_path
        st.image(temp_path, width=64)
    elif st.session_state.assistant_icon_path:
        st.image(st.session_state.assistant_icon_path, width=64)

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§æ ¼
    st.session_state.assistant_persona = st.text_area(
        "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ€§æ ¼ãƒ»ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        st.session_state.assistant_persona,
        height=120,
    )

    st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ (å¤‰æ›´ã¯å³æ™‚åæ˜ ã•ã‚Œã¾ã™)")
